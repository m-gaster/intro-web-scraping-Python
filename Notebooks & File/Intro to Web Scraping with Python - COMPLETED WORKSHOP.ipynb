{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics Of Web-Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Am I allowed to access this data? \n",
    "    * https://www.chefknivestogo.com/robots.txt\n",
    "* Can the site handle my requests?\n",
    "    * https://www.nrcs.usda.gov/robots.txt\n",
    "* Can I use it in my research? What can I use it for?\n",
    "    * https://meta.wikimedia.org/wiki/Terms_of_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is a Jupyter notebook!\n",
    "* Interactive. Popular in data science\n",
    "* Used with Python, R, Julia.\n",
    "* Mine looks slightly different\n",
    "* Command vs. Edit mode\n",
    "* Blocks are called \"cells\".\n",
    "    * Run cells: ctrl/cmd + enter/return\n",
    "    * New cells above: ctrl/cmd + a \n",
    "    * Code vs. md.\n",
    "* Is it running?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background: Functions, Data Types, and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### int (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### float (number with decimal point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bool (True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(True))\n",
    "\n",
    "# bools can act as ones (True) and zeros (False)\n",
    "print(True + True)\n",
    "\n",
    "print(False + False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### str (characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type('a string'))\n",
    "\n",
    "test_str = 'a string'\n",
    "\n",
    "print(len(test_str))\n",
    "\n",
    "print(test_str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list\n",
    "\n",
    "* Store multiple items (elements) in a single variable, e.g., three integers (ints). \n",
    "* Elements are separated by commas.\n",
    "\n",
    "**Note that indices start at 0 in Python!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize a list\n",
    "test_list = [5, 25, 125]\n",
    "\n",
    "# print the list\n",
    "print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the 0th element\n",
    "print(test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length of the list (number of elements in it)\n",
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists can have mixed datatypes (pretty much anything can be put in a list)\n",
    "test_list_2 = ['a', 2, [4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add two lists together\n",
    "# technically, this is called \"concatenating\" the first and second lists\n",
    "\n",
    "print(test_list + test_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension is an easy way to modify and/or filter lists\n",
    "# GENERAL SYNTAX: \n",
    "    # new_list = [x for x in old_list]\n",
    "\n",
    "# use list comprehension to recreate the same list (just to show how it works)\n",
    "print([y for y in test_list])\n",
    "\n",
    "# use list comprehension to add five to each element\n",
    "print([x+5 for x in test_list])\n",
    "\n",
    "# use list comprehension to add five to each element, AND filter them\n",
    "print([x+5 for x in test_list if (x==0 or x==1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dict (dictionary)\n",
    "\n",
    "* A dictionary is a correspondence of key:value pairings which allow you to look up values from keys!\n",
    "* Keys and values can be most datatypes\n",
    "* Keys must be unique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a dictionary. \n",
    "test_dict = {'key1':'value1', 2:'value2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up first value via key\n",
    "print(test_dict['key1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can only do dict[key] to get value. CANNOT do dict[value] to get key\n",
    "print(test_dict['value1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Functions are reusable blocks of code which let you repeat the same task without rewriting all that code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function to add five\n",
    "def add_five(number):\n",
    "    return number + 5\n",
    "\n",
    "# try applying the function\n",
    "print(add_five(100))\n",
    "\n",
    "# apply the function to a list\n",
    "print(test_list)\n",
    "print([add_five(x) for x in test_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "* 2-D tabular data variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pandas dataframe from dictionary. note that lists must be the same length!\n",
    "\n",
    "# initialize example dict\n",
    "test_dict = {'col1':[1,2,3], 'col2':[4,5,6]}\n",
    "\n",
    "# initialize pd.DataFrame\n",
    "test_df = pd.DataFrame(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty-print test_df\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access a specific column of the dataframe\n",
    "test_df['col1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the first row\n",
    "test_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to the existing dataframe\n",
    "test_df['new col'] = ['a', [1,2], 3]\n",
    "\n",
    "# print\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column in the existing dataframe - by applying a function to a column\n",
    "test_df['col1 + 5'] = test_df['col1'].apply(add_five)\n",
    "\n",
    "# print\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import Necessary packages\n",
    "\n",
    "Earlier, we *installed* the necessary packages with the \"pip install [package]\" commands\n",
    "\n",
    "Now, we *import* the packages so we can use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pd.read_html() - USDA FIPS\n",
    "\n",
    "* URL\n",
    "    * https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697\n",
    "* Are we supposed to do something here?\n",
    "    * https://www.nrcs.usda.gov/robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's where we start using the \"pandas\" package\n",
    "\n",
    "# import data from USDA. Output is a LIST of dataframes (tables) that pandas found at the URL\n",
    "usda_fips_list = pd.read_html(\"https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print output to see what we have...\n",
    "usda_fips_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine the zero-th element in the list (have to start somewhere!)\n",
    "usda_fips_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# take the fips table we want\n",
    "usda_fips = usda_fips_list[0]\n",
    "\n",
    "# delete the (now-redundant) variable holding the rest of the tables\n",
    "del usda_fips_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last row is incorrect, so let's delete it\n",
    "\n",
    "# here's what the dataframe looks like without the last column\n",
    "usda_fips.drop(3232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looks good so let's make this a permanent change!\n",
    "usda_fips = usda_fips.drop(3232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm there are no other rows we need to drop. Check for nan values in any col pt. 1\n",
    "usda_fips.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nan values in any col pt. 2\n",
    "usda_fips.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's examine the dataframe more closely to make sure everything is correct\n",
    "\n",
    "# change display options to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "usda_fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the table looks good so let's save it as a .csv and move on\n",
    "usda_fips.to_csv(\"USDA FIPS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pd.read_html() -  Wikipedia FIPS\n",
    "\n",
    "Same data, different source.\n",
    "\n",
    "This one needs more processing/cleaning\n",
    "\n",
    "* URL\n",
    "    * https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county\n",
    "* robots.txt\n",
    "    * https://en.wikipedia.org/robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from wikipedia. Again, output is a LIST of dataframes (tables)\n",
    "wiki_fips_list = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's print the output and take a look...\n",
    "wiki_fips_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-th element (table)?\n",
    "wiki_fips_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first element (table)?\n",
    "wiki_fips_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign correctly parsed table to variable\n",
    "wiki_fips = wiki_fips_list[1]\n",
    "\n",
    "# remove all hyperlinks (these look like \"... County [h]\", etc.)\n",
    "## this is done by using \"regex\", and there is an intro to regex workshop on August 10th - https://libcal.library.ubc.ca/event/3615287\n",
    "wiki_fips['County or equivalent'] = wiki_fips['County or equivalent'].str.replace(r\"\\[.*\\]\",\"\")\n",
    "\n",
    "wiki_fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function convert to uppercase\n",
    "def make_uppercase(string):\n",
    "    return string.upper()\n",
    "\n",
    "# apply the uppercase function\n",
    "wiki_fips['County or equivalent'] = wiki_fips['County or equivalent'].apply(make_uppercase)\n",
    "wiki_fips['State or equivalent'] = wiki_fips['State or equivalent'].apply(make_uppercase)\n",
    "\n",
    "# replace \"St.\" with \"Saint\"\n",
    "wiki_fips['County or equivalent'] = [x.replace('ST.','SAINT') for x in wiki_fips['County or equivalent']]\n",
    "\n",
    "# remove everything after a comma in a county name (e.g. \"ANCHORAGE, MUNICIPALITY OF\")\n",
    "wiki_fips['County or equivalent'] = [x.split(',')[0] for x in wiki_fips['County or equivalent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to .csv\n",
    "wiki_fips.to_csv(\"Wikipedia FIPS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request  + BeautifulSoup\n",
    "\n",
    " Red-bellied Snake (Wikipedia) Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squirrel Article (Wikipedia) Text Analysis\n",
    "\n",
    "Hypothetical: we want to get a list of all words (and their respective frequencies) from this wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use requests to get URL\n",
    "wiki_squirrel_response = requests.get(\"https://en.wikipedia.org/wiki/Squirrel\")\n",
    "\n",
    "# it prints \"200\" if the page was successfully downloaded!\n",
    "print(wiki_squirrel_response)\n",
    "\n",
    "# another way to check it worked - we can just ask :)\n",
    "print(wiki_squirrel_response.ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's examine the output... which turns out to be a mess (this is where BeautifulSoup becomes necessary)\n",
    "wiki_squirrel_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use BeautifulSoup's html parser to convert the html document into a BeautifulSoup object\n",
    "wiki_squirrel_soup = BeautifulSoup(wiki_squirrel_response.text, 'html.parser')\n",
    "\n",
    "# why use 'html.parser'? \n",
    "    # https://stackoverflow.com/a/60254943/11595913\n",
    "\n",
    "# BeautifulSoup sometimes gives us a more readable format, but not this time - the BeautifulSoup object () is no more readable than the \n",
    "wiki_squirrel_soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to isolate the article's text and get rid of the rest! we'll do that by getting all html elements with a \"p\" (paragraph) tag\n",
    "for paragraph in wiki_squirrel_soup.find_all('p'):\n",
    "    print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the text out of each of these paragraph elements\n",
    "\n",
    "for paragraph in wiki_squirrel_soup.find_all('p'):\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we need to take all of these paragraphs and merge them into one large string (remember our overall goal)\n",
    "\n",
    "wiki_squirrel_text = ' '.join([paragraph.text for paragraph in wiki_squirrel_soup.find_all('p')])\n",
    "\n",
    "wiki_squirrel_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's count occurences of each word\n",
    "# this is where we use the \"nltk\" package.\n",
    "# import nltk\n",
    "\n",
    "nltk.FreqDist(wiki_squirrel_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the FreqDist input by word\n",
    "split_wiki_squirrel_text = wiki_squirrel_text.split()\n",
    "\n",
    "# print \n",
    "print(split_wiki_squirrel_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try FreqDist again\n",
    "wiki_squirrel_word_freqs = nltk.FreqDist(split_wiki_squirrel_text)\n",
    "\n",
    "# print\n",
    "wiki_squirrel_word_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict --> pd.DataFrame\n",
    "wiki_squirrel_df = pd.DataFrame({'Word': wiki_squirrel_word_freqs.keys(), 'Frequency': wiki_squirrel_word_freqs.values()})\n",
    "\n",
    "# print\n",
    "wiki_squirrel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort\n",
    "wiki_squirrel_df = wiki_squirrel_df.sort_values('Frequency', ascending=False)\n",
    "\n",
    "wiki_squirrel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's convert frequency into a percentage\n",
    "\n",
    "# first, total up the number of words\n",
    "wiki_squirrel_total_num_words = wiki_squirrel_df['Frequency'].sum()\n",
    "\n",
    "# make a % frequency column in wiki_squirrel_df\n",
    "wiki_squirrel_df['% Freq'] = (wiki_squirrel_df['Frequency'] / wiki_squirrel_total_num_words) * 100\n",
    "\n",
    "# print\n",
    "wiki_squirrel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot word frequency\n",
    "wiki_squirrel_df.plot.bar(x='Word', y='Frequency', figsize=(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a better plot of word frequency\n",
    "wiki_squirrel_df[wiki_squirrel_df['% Freq'] > .5].plot.bar(x='Word', y='Frequency', figsize=(9,6), rot=45)#, log=True)\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Zipf%27s_law  ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart (notice caps)\n",
    "wiki_squirrel_df[wiki_squirrel_df['% Freq'] > 1].set_index('Word').plot.pie(y='% Freq', figsize=(9,6), legend=False)\n",
    "\n",
    "# wiki_squirrel_df.set_index('Word').plot.pie(y='% Freq', figsize=(9,6), legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to .csv\n",
    "wiki_squirrel_df.to_csv(\"Squirrel Words & Frequencies.csv\")\n",
    "\n",
    "# save to .json\n",
    "wiki_squirrel_df.to_json(\"Squirrel Words & Frequencies.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request  + BeautifulSoup - lichess.org user stats\n",
    "\n",
    "Let's get the information of every top \"bullet\" chess player\n",
    "\n",
    "Our approach:\n",
    "* Get the list of top bullet players\n",
    "    * Listed at https://lichess.org/player/top/200/bullet\n",
    "* Go to each player's account\n",
    "    * Account page URLs have the following structure: \"https://lichess.org/@/\" + username\n",
    "    * E.g., https://lichess.org/@/RebeccaHarris\n",
    "* Scrape the information from each player's account and compile it into a pandas DataFrame\n",
    "    * Do this by writing several functions to get specific pieces of information\n",
    "* Save the dataframe as a .csv file\n",
    "\n",
    "\n",
    "**NOTE: THIS EXERCISE USES SELECTOR GADGET TO FIND HTML ELEMENTS: https://selectorgadget.com/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile list of usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the top bullet players: https://lichess.org/player/top/200/bullet\n",
    "\n",
    "# scrape this table!\n",
    "players_df_list = pd.read_html(\"https://lichess.org/player/top/200/bullet\")\n",
    "\n",
    "# let's see the output:\n",
    "players_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like we only need/want the first dataframe in this list (turns out there's only one anyway)\n",
    "players_df = players_df_list[0]\n",
    "\n",
    "# delete the list of dataframes\n",
    "del players_df_list\n",
    "\n",
    "# print\n",
    "players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column called 0 is the user's ranking, and the column called 3 is their recent rating change. we aren't interested in either, so let's delete them\n",
    "del players_df[0], players_df[3]\n",
    "\n",
    "players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's rename the columns to more helpful labels pt.1 \n",
    "\n",
    "# print the renamed dataframe to make sure it looks good\n",
    "players_df.rename(columns={1:'User', 2:'Rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's rename the columns to more helpful labels pt.2\n",
    "\n",
    "# now replace the dataframe with the renamed dataframe\n",
    "players_df = players_df.rename(columns={1:'User', 2:'Rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a short function to give us individual players' urls from username, for convenience\n",
    "def indiv_URL_formula(username):\n",
    "    return \"https://lichess.org/@/\" + username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of first user's account\n",
    "# \"https://lichess.org/@/\" + ' '.join(players_df['User'].iloc[0].split())\n",
    "indiv_URL_formula(players_df['User'].iloc[0])\n",
    "\n",
    "# equivalent to: \"https://lichess.org/@/\" + players_df['User'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to somehow replace these \"/xa0\" parts of the string.\n",
    "# these are not dumplings! they're actually non-character breaking spaces (not important to know what that means)\n",
    "\n",
    "def replace_xa0(username):\n",
    "    '''\n",
    "    input = a player's username (string)\n",
    "    output = a player's username, with \"\\xa0\" replaced by \" \"\n",
    "    '''\n",
    "    return username.replace(\"\\xa0\", \" \")\n",
    "\n",
    "# apply this function to our dataframe\n",
    "## first, let's check to see that it returns the right output\n",
    "players_df['User'].apply(replace_xa0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## looks good (or at least not harmful), so let's replace the username\n",
    "players_df['User'] = players_df['User'].apply(replace_xa0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retry printing url of first user's account\n",
    "indiv_URL_formula(players_df['User'].iloc[0])\n",
    "\n",
    "# this still doesn't work! there's a \"GM\" title in the URL, as well as a space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to split the \"User\" column, otherwise we get urls like \"https://lichess.org/@/GM RebeccaHarris\" instead of \"https://lichess.org/@/RebeccaHarris\"\n",
    "\n",
    "def get_user(title_user_str):\n",
    "    \"\"\"\n",
    "    title_user_str looks like \"GM RebeccaHarris\" or \"Shprot86\"\n",
    "    \"\"\"\n",
    "    if len(title_user_str.split())==2:     # if the user is titled (has two words in their user field, rather than one)\n",
    "        return title_user_str.split()[1]       # return their username\n",
    "    else:                                  # if the user is not titled (has one word in their user field)\n",
    "        return title_user_str                  # return the input string, since it is already their username without a title\n",
    "\n",
    "\n",
    "def get_title(title_user_str):\n",
    "    \"\"\"\n",
    "    title_user_str looks like \"GM RebeccaHarris\" or \"Shprot86\"\n",
    "    \"\"\"\n",
    "    if len(title_user_str.split())==2:    # if the user is titled (has two words in their user field, rather than one)\n",
    "        return title_user_str.split()[0]      #return their title\n",
    "    else:                                 # if the user is not titled (has one word in their user field)\n",
    "        return  np.nan                        #return a missing value\n",
    "\n",
    "    \n",
    "# apply these functions to the \"User\" column to create a new column for Usernames and a new column for titles\n",
    "players_df['Username'] = players_df['User'].apply(get_user)\n",
    "players_df['Title'] = players_df['User'].apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the dataframe to make sure everything worked\n",
    "players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a \"URL\" column by applying the \"indiv_URL_formula\" function we defined earlier\n",
    "players_df['URL'] = players_df['Username'].apply(indiv_URL_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print df\n",
    "players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print URLs\n",
    "players_df['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to .csv\n",
    "players_df.to_csv(r\"Top 200 Players.csv\", index=False)\n",
    "\n",
    "# read from .csv\n",
    "players_df = pd.read_csv(r\"Top 200 Players.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Write functions to get statistics/info from individual pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a short function to give us individual players' urls from username, for convenience\n",
    "def indiv_URL_formula(username):\n",
    "    return \"https://lichess.org/@/\" + username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# let's scrape the first user's page so we have an example to work with\n",
    "# after figuring out how to scrape the first user's site, we'll use the same methods to scrape the rest\n",
    "\n",
    "# first_player_url = indiv_URL_formula(players_df['Username'].iloc[0])\n",
    "\n",
    "first_player_url = \"https://lichess.org/@/Zhigalko_Sergei\"\n",
    "print(first_player_url)\n",
    "\n",
    "# use requests to get html\n",
    "first_player_response = requests.get(first_player_url)\n",
    "\n",
    "# create beautifulsoup object for \n",
    "first_player_soup = BeautifulSoup(first_player_response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Get user's name (if they provide one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# use selector gadget to identify the elements we need\n",
    "\n",
    "# select html elements - note that this always returns a LIST, even when there's only one element in the list\n",
    "print(first_player_soup.select('.name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get text from selected html elements\n",
    "print([x.text for x in first_player_soup.select('.name')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the lone string out of this list (it's the only element)\n",
    "print([x.text for x in first_player_soup.select('.name')][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# take what we just did and turn it into a function\n",
    "def get_name(player_soup):\n",
    "    try:\n",
    "        return [x.text for x in player_soup.select(\".name\")][0]\n",
    "    except:\n",
    "        return np.nan #return a missing value if there's no name on the lichess user's page\n",
    "    \n",
    "\n",
    "# apply this function to make sure it works as intended\n",
    "get_name(first_player_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Get number of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# use selector gadget to identify the elements we need\n",
    "\n",
    "# select html elements\n",
    "print(first_player_soup.select('.user-show__social .nm-item:nth-child(1)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print text from selected elements to make sure it's correct\n",
    "[x.text for x in first_player_soup.select('.user-show__social .nm-item:nth-child(1)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# take follower string out of list\n",
    "num_followers = [x.text for x in first_player_soup.select('.user-show__social .nm-item:nth-child(1)')][0]\n",
    "num_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# split followers string at the letter \"f\" to isolate the numbers\n",
    "num_followers = num_followers.split('f')[0]\n",
    "\n",
    "# print\n",
    "num_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove comma from number\n",
    "num_followers = num_followers.replace(',','')\n",
    "\n",
    "# print\n",
    "num_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert the string to an integer\n",
    "num_followers = int(num_followers)\n",
    "\n",
    "# print\n",
    "num_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# take what we just did (to get number of followers) and turn it into a function\n",
    "def get_num_followers(player_soup):\n",
    "    num_followers = player_soup.select('.user-show__social .nm-item:nth-child(1)')\n",
    "                                        \n",
    "    num_followers = [x.text for x in num_followers]\n",
    "    \n",
    "    num_followers = num_followers[0].split('f')[0]\n",
    "    \n",
    "    num_followers = num_followers.replace(',', '')\n",
    "    \n",
    "    num_followers = int(num_followers)\n",
    "    \n",
    "    return num_followers\n",
    "\n",
    "# check that it works!\n",
    "get_num_followers(first_player_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Get number of games played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# select number of games element\n",
    "num_games = first_player_soup.select('.to-games')\n",
    "\n",
    "# print\n",
    "num_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get text from the html elements we selected\n",
    "num_games = [x.text for x in num_games]\n",
    "\n",
    "# print\n",
    "num_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# take lone element out of list\n",
    "num_games = num_games[0]\n",
    "\n",
    "# print\n",
    "num_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# take the number out of the string\n",
    "\n",
    "# first, split the string\n",
    "num_games = num_games.split()\n",
    "\n",
    "# print\n",
    "print(num_games)\n",
    "\n",
    "# then, take the first element\n",
    "num_games = num_games[0]\n",
    "\n",
    "# print\n",
    "num_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove comma from number string\n",
    "num_games = num_games.replace(',', '')\n",
    "\n",
    "# print\n",
    "num_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert string to int\n",
    "num_games = int(num_games)\n",
    "\n",
    "# print\n",
    "num_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# take what we just did (to get number of games played) and turn it into a function\n",
    "def get_num_games(player_soup):\n",
    "    num_games = player_soup.select('.to-games')\n",
    "\n",
    "    num_games = [x.text for x in num_games]\n",
    "\n",
    "    num_games = num_games[0]\n",
    "\n",
    "    num_games = num_games.split()\n",
    "\n",
    "    num_games = num_games[0]\n",
    "\n",
    "    num_games = num_games.replace(',', '')\n",
    "\n",
    "    num_games = int(num_games)\n",
    "\n",
    "    return num_games\n",
    "\n",
    "# make sure it works\n",
    "get_num_games(first_player_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the scraping functions we made, use them in one big function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SCRAPING FUNCTION\n",
    "\n",
    "# we need to add a delay between our requests. the \"time\" package allows us to easily do this\n",
    "import time\n",
    "\n",
    "def scrape_all_user_stats(df):\n",
    "    '''\n",
    "    input = dataframe containing a column called \"URL\", which holds user acct. URLs\n",
    "    output = input dataframe + scraped columns\n",
    "    '''\n",
    "    # we will hold the scraped information in a dictionary until we're ready to merge it back with the original players_df\n",
    "    scraped_info_dict = {'Name': [], \n",
    "                         'Num. Games': [],\n",
    "                        'Num. Followers': []}\n",
    "    \n",
    "    # loop over every player's URL in the input dataframe\n",
    "    for player_url in df['URL']:\n",
    "\n",
    "        # delay 2 seconds betweeneach loop\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # print the URL just so we can see the player\n",
    "        print(player_url)\n",
    "        \n",
    "        # use \"requests\" to access webpage\n",
    "        this_player_response = requests.get(player_url)\n",
    "\n",
    "        # convert to \"BeautifulSoup\" object\n",
    "        this_player_soup = BeautifulSoup(this_player_response.text, 'html.parser')\n",
    "\n",
    "        # get name\n",
    "        scraped_info_dict['Name'].append(get_name(this_player_soup))\n",
    "\n",
    "        # get number of games\n",
    "        scraped_info_dict['Num. Games'].append(get_num_games(this_player_soup))\n",
    "\n",
    "        # get number of followers\n",
    "        scraped_info_dict['Num. Followers'].append(get_num_followers(this_player_soup))\n",
    "    \n",
    "    # we now have a dictionary (scraped_info_dict) which holds the scraped information.\n",
    "        # (specifically, it holds three lists - \"Name\", \"Num. Games\", and \"Num Followers\" - which hold the scraped info)\n",
    "    # we convert this dictionary into a pandas dataframe so it can be easily merged with the original players_df dataframe\n",
    "    \n",
    "    # dict --> dataframe\n",
    "    scraped_info_df = pd.DataFrame(scraped_info_dict)\n",
    "    \n",
    "    # merge the two dataframes (original and new information)\n",
    "    merged_df = pd.concat([df, scraped_info_df], axis=1)\n",
    "        \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test output\n",
    "first_five_players = players_df.head(5)\n",
    "\n",
    "lichess_test_scrape = scrape_all_user_stats(first_five_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print our final dataframe and see what it looks like\n",
    "lichess_test_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot num followers against rating\n",
    "lichess_test_scrape.plot.scatter(x='Rating', y='Num. Followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lichess_test_scrape['Rating'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lichess_scrape = scrape_all_user_stats(players_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print output (make sure it looks good!)\n",
    "final_lichess_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output to .csv\n",
    "final_lichess_scrape.to_csv(\"Lichess Scrape.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of ratings\n",
    "final_lichess_scrape['Rating'].hist(bins=20, rwidth=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot num followers against rating (scatter plot)\n",
    "final_lichess_scrape.plot.scatter(x='Rating', y='Num. Followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot num followers against rating (scatter plot) - BY TITLE\n",
    "for title in final_lichess_scrape['Title'].unique(): # \".unique\" gets all of the unique values in the column - in this case, titles\n",
    "    print(title)\n",
    "    \n",
    "# need this to display plots in a loop    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loop over each type of title\n",
    "for title in final_lichess_scrape['Title'].unique():\n",
    "    \n",
    "    # if the title isn't NaN\n",
    "    if not pd.isnull(title): \n",
    "        \n",
    "        # plot users with this title\n",
    "        final_lichess_scrape[final_lichess_scrape['Title']==title].plot.scatter(x='Rating', y='Num. Followers', title=title, xlim=(2750,3100))\n",
    "        \n",
    "        # show the plot\n",
    "        plt.show()\n",
    "    \n",
    "    # else, if the title IS NaN\n",
    "    else:\n",
    "        \n",
    "        # plot users with no title (add a manually entered plot title)\n",
    "        final_lichess_scrape[pd.isnull(final_lichess_scrape['Title'])].plot.scatter(x='Rating', y='Num. Followers', title='No Title', xlim=(2750,3100))\n",
    "        \n",
    "        # show the plot\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
